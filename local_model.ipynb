{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a5f0e7",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError, MeanIoU\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c19a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir las GPUs disponibles\n",
    "print(\"GPUs disponibles:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Configurar la GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Configura el crecimiento de memoria para evitar la asignación total\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)  # Habilitar crecimiento de memoria dinámico\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error al configurar el crecimiento de memoria: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b3af64",
   "metadata": {},
   "source": [
    "# Leer archivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19cbb94",
   "metadata": {},
   "source": [
    "## Funciones de lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab04857",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 288  # Ancho menor que altura (formato celular)\n",
    "\n",
    "input_dir = \"input/combined/\"\n",
    "target_dir = \"target/semantic_annotations\"\n",
    "\n",
    "def count_unique_colors(image_path):\n",
    "    img = cv2.imread(image_path)  # Leer en BGR\n",
    "    if img is None:\n",
    "        return 0\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convertir a RGB\n",
    "    img = img.reshape(-1, 3)  # Aplanar\n",
    "    unique_colors = np.unique(img, axis=0)\n",
    "    return len(unique_colors)\n",
    "\n",
    "def is_well_segmented(image_path, threshold=2):\n",
    "    unique_colors = count_unique_colors(image_path)\n",
    "    return unique_colors > threshold\n",
    "\n",
    "def load_image_pair(num_image):\n",
    "    input_path = os.path.join(input_dir, f\"{num_image}.jpg\")\n",
    "    target_path = os.path.join(target_dir, f\"{num_image}.png\")\n",
    "    \n",
    "    if not is_well_segmented(target_path):\n",
    "        return None, None\n",
    "\n",
    "    input_img = cv2.imread(input_path)\n",
    "    if input_img is None:\n",
    "        return None, None\n",
    "    input_img = cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)\n",
    "    input_img = cv2.resize(input_img, (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0\n",
    "\n",
    "    target_img = cv2.imread(target_path)\n",
    "    if target_img is None:\n",
    "        return None, None\n",
    "    target_img = cv2.cvtColor(target_img, cv2.COLOR_BGR2RGB)\n",
    "    target_img = cv2.resize(target_img, (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0\n",
    "\n",
    "    return input_img, target_img\n",
    "\n",
    "def load_image_pair_gray(num_image):\n",
    "    input_path = os.path.join(input_dir, f\"{num_image}.jpg\")\n",
    "    target_path = os.path.join(target_dir, f\"{num_image}.png\")\n",
    "    \n",
    "    if not is_well_segmented(target_path):\n",
    "        return None, None\n",
    "\n",
    "    input_img = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "    target_img = cv2.imread(target_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if input_img is None or target_img is None:\n",
    "        return None, None\n",
    "\n",
    "    input_img = cv2.resize(input_img, (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0\n",
    "    target_img = cv2.resize(target_img, (IMG_WIDTH, IMG_HEIGHT)).astype(np.float32) / 255.0\n",
    "\n",
    "    input_img = np.expand_dims(input_img, axis=-1)\n",
    "    target_img = np.expand_dims(target_img, axis=-1)\n",
    "\n",
    "    return input_img, target_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e895ec1",
   "metadata": {},
   "source": [
    "## Ejemplo de lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de visualización\n",
    "X_example, Y_example = load_image_pair(3)\n",
    "\n",
    "if X_example is not None and Y_example is not None:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Input\")\n",
    "    plt.imshow(X_example)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.imshow(Y_example)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"La imagen no está bien segmentada o no se pudo cargar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e40cf7",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf6f0b",
   "metadata": {},
   "source": [
    "## Creacion modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdf48ac",
   "metadata": {},
   "source": [
    "### Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(inputs, num_filters):\n",
    "\n",
    "    # Convolution with 3x3 filter followed by ReLU activation\n",
    "    x = tf.keras.layers.Conv2D(num_filters, 3, padding='same')(inputs)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    # Convolution with 3x3 filter followed by ReLU activation\n",
    "    x = tf.keras.layers.Conv2D(num_filters, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # Convolution with 3x3 filter followed by ReLU activation    \n",
    "    p = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2)(x)\n",
    "    return x, p  # <-- x es skip connection, p va al siguiente encoder\n",
    "\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    \n",
    "    # Upsampling layer with 2x2 filter and stride of 2\n",
    "    x = tf.keras.layers.Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')(inputs)\n",
    "    \n",
    "    # Concatenate the skip features with the upsampled input\n",
    "    x = tf.keras.layers.Concatenate()([x, skip_features])\n",
    "    \n",
    "    # Convolution with 3x3 filter followed by ReLU activation\n",
    "    x = tf.keras.layers.Conv2D(num_filters, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # Convolution with 3x3 filter followed by ReLU activation\n",
    "    x = tf.keras.layers.Conv2D(num_filters, 3, padding='same')(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c16d4",
   "metadata": {},
   "source": [
    "### Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde74a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_shape = (512, 288, 3), num_classes = 1, base_filters = 16):\n",
    "    inputs = tf.keras.layers.Input(input_shape) # Shape: (512, 288, 3)\n",
    "\n",
    "    # Contracting Path\n",
    "    s1, p1 = encoder_block(inputs, base_filters) # Shape: (512, 288, 3) -> (256, 144, 16)\n",
    "    s2, p2 = encoder_block(p1, base_filters * 2) # Shape: (256, 144, 16) -> (128, 72, 32)\n",
    "    s3, p3 = encoder_block(p2, base_filters * 4) # Shape: (128, 72, 32) -> (64, 36, 64)\n",
    "    s4, p4 = encoder_block(p3, base_filters * 8) # Shape: (64, 36, 64) -> (32, 18, 128)\n",
    "    \n",
    "    # Bottleneck\n",
    "    b1 = tf.keras.layers.Conv2D(base_filters * 16, 3, padding='same')(p4)\n",
    "    b1 = tf.keras.layers.Activation('relu')(b1) # Shape: (32, 18, 128) -> (32, 18, 256)\n",
    "    b1 = tf.keras.layers.Conv2D(base_filters * 16, 3, padding='same')(b1)\n",
    "    b1 = tf.keras.layers.Activation('relu')(b1) # Shape: (32, 18, 256) -> (32, 18, 256)\n",
    "    \n",
    "    # Expansive Path\n",
    "    d1 = decoder_block(b1, s4, base_filters * 8) # Shape: (32, 18, 256) -> (64, 36, 128)\n",
    "    d2 = decoder_block(d1, s3, base_filters * 4) # Shape: (64, 36, 128) -> (128, 72, 64)\n",
    "    d3 = decoder_block(d2, s2, base_filters * 2) # Shape: (128, 72, 64) -> (256, 144, 32)\n",
    "    d4 = decoder_block(d3, s1, base_filters) # Shape: (256, 144, 32) -> (512, 288, 16)\n",
    "    \n",
    "    # Output\n",
    "    outputs = tf.keras.layers.Conv2D(num_classes, 1, padding = 'same', activation = 'softmax')(d4) # Shape: (512, 288, 16) -> (512, 288, 1)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = inputs, outputs = outputs, name = 'U-Net')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d23b2b4",
   "metadata": {},
   "source": [
    "## Compilacion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e88495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), num_classes=24, base_filters=16)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=[MeanIoU(num_classes=24)]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d0fdc",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuración de entrenamiento y checkpoints globales ---\n",
    "save_dir = 'model/rico/unet'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "best_model_path = os.path.join(save_dir, 'best_model_overall.keras')\n",
    "last_model_path = os.path.join(save_dir, 'last_batch_model.keras')\n",
    "\n",
    "# Callback para guardar el mejor modelo de TODOS los batches\n",
    "global_callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss'),\n",
    "    ModelCheckpoint(best_model_path, save_best_only=True, monitor='val_loss')\n",
    "]\n",
    "\n",
    "total_images   = 20000\n",
    "batch_size     = 10\n",
    "ignored_images = 0\n",
    "\n",
    "for batch_start in range(0, total_images, batch_size):\n",
    "    print(f\"\\n--- Procesando lote {batch_start} a {batch_start + batch_size} ---\")\n",
    "\n",
    "    X_batch, Y_batch = [], []\n",
    "    for i in range(batch_start, batch_start + batch_size):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"  Procesando imagen {i}\")\n",
    "        x, y = load_image_pair(i)\n",
    "        if x is None or y is None:\n",
    "            ignored_images += 1\n",
    "            continue\n",
    "        X_batch.append(x)\n",
    "        Y_batch.append(y)\n",
    "\n",
    "    X_batch = np.array(X_batch, dtype=np.float32)\n",
    "    Y_batch = np.array(Y_batch, dtype=np.float32)\n",
    "    print(f\"  Total imágenes cargadas: {len(X_batch)} (Ignoradas hasta ahora: {ignored_images})\")\n",
    "\n",
    "    # Split train/val\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "        X_batch, Y_batch, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Entrena sobre este batch, pero usa callbacks globales para actualizar el mejor modelo\n",
    "    model.fit(\n",
    "        X_train, Y_train,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        batch_size=4,\n",
    "        epochs=50,\n",
    "        callbacks=global_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "# Al terminar TODOS los batches, guardamos también el estado final (último batch)\n",
    "model.save(last_model_path)\n",
    "print(f\"\\nMejor modelo guardado en: {best_model_path}\")\n",
    "print(f\"Modelo del último batch guardado en: {last_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a79afa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ruta a los modelos guardados\n",
    "model_dir = \"model/rico\"\n",
    "model_files = sorted([\n",
    "    f for f in os.listdir(model_dir)\n",
    "    if f.endswith(\".keras\") and f.startswith(\"best_model_batch_\")\n",
    "])\n",
    "\n",
    "# 2. Cargar imágenes de test (una sola vez)\n",
    "print(\"\\n--- Cargando imágenes de test ---\")\n",
    "X_test, Y_test = [], []\n",
    "eval_start = total_images  # Asegúrate que esta variable esté definida\n",
    "eval_end = total_images + 10  # Evaluaremos con 500 imágenes\n",
    "ignored_eval = 0\n",
    "\n",
    "for i in range(eval_start, eval_end):\n",
    "    x, y = load_image_pair(i)\n",
    "    if x is None or y is None:\n",
    "        ignored_eval += 1\n",
    "        continue\n",
    "    X_test.append(x)\n",
    "    Y_test.append(y)\n",
    "\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "Y_test = np.array(Y_test, dtype=np.float32)\n",
    "print(f\"  Total test cargadas: {len(X_test)} (Ignoradas en test: {ignored_eval})\")\n",
    "\n",
    "# 3. Evaluar todos los modelos\n",
    "resultados = []\n",
    "\n",
    "for model_file in model_files:\n",
    "    model_path = os.path.join(model_dir, model_file)\n",
    "    print(f\"\\n--- Evaluando modelo: {model_file} ---\")\n",
    "    try:\n",
    "        model = tf.keras.models.load_model(model_path, compile=True)\n",
    "        metrics = model.evaluate(X_test, Y_test, verbose=0)  # silencioso\n",
    "        resultados.append((model_file, metrics))\n",
    "        print(f\"  Métricas: {metrics}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Error al cargar o evaluar {model_file}: {e}\")\n",
    "\n",
    "# 4. Ordenar modelos por la primera métrica (usualmente loss)\n",
    "resultados_ordenados = sorted(resultados, key=lambda x: x[1][0])  # menor loss\n",
    "\n",
    "# 5. Mostrar ranking\n",
    "print(\"\\n📊 Ranking de modelos por pérdida (menor es mejor):\")\n",
    "for rank, (name, metrics) in enumerate(resultados_ordenados):\n",
    "    print(f\"{rank+1}. {name}: loss={metrics[0]:.4f}, otras métricas={metrics[1:]}\")\n",
    "\n",
    "# 6. (Opcional) Guardar en archivo\n",
    "with open(\"ranking_modelos.txt\", \"w\") as f:\n",
    "    f.write(\"Modelo\\tLoss\\tMétricas adicionales\\n\")\n",
    "    for name, metrics in resultados_ordenados:\n",
    "        f.write(f\"{name}\\t{metrics[0]:.4f}\\t{metrics[1:]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaaf4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"model/rico/best_model_batch_1500.keras\", compile=True)\n",
    "def show_prediction(idx):\n",
    "    x, y = load_image_pair(idx)\n",
    "    if x is None or y is None:\n",
    "        print(\"No se pudo cargar la imagen o no está bien segmentada.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Formato de entrada (original): {x.shape}, Formato de salida: {y.shape}\")\n",
    "    print(\"Tipo de x:\", type(x), \"| dtype:\", x.dtype)\n",
    "\n",
    "    # Verifica que esté en el formato correcto\n",
    "    if x.shape != (512, 288, 3):\n",
    "        print(\"Redimensionando x...\")\n",
    "        x = tf.image.resize(x, (512, 288)).numpy()\n",
    "    if y.shape != (512, 288, 3):\n",
    "        print(\"Redimensionando y...\")\n",
    "        y = tf.image.resize(y, (512, 288)).numpy()\n",
    "\n",
    "    # Normaliza si es necesario\n",
    "    if x.max() > 1.0:\n",
    "        x = x / 255.0\n",
    "\n",
    "    # Asegura que tenga la dimensión de batch\n",
    "    x_batch = np.expand_dims(x, axis=0)\n",
    "    print(\"Forma para predicción:\", x_batch.shape)\n",
    "\n",
    "    # Predicción\n",
    "    pred = model.predict(x_batch)[0]\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Input\")\n",
    "    plt.imshow(x)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.imshow(y)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(pred)\n",
    "    plt.show()\n",
    "\n",
    "show_prediction(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b8948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación final con imágenes no vistas\n",
    "print(\"\\n--- Evaluando modelo con 500 imágenes nuevas ---\")\n",
    "X_test, Y_test = [], []\n",
    "eval_start = total_images\n",
    "eval_end = total_images + 10\n",
    "ignored_eval = 0\n",
    "\n",
    "for i in range(eval_start, eval_end):\n",
    "    x, y = load_image_pair(i)\n",
    "    if x is None or y is None:\n",
    "        ignored_eval += 1\n",
    "        continue\n",
    "    X_test.append(x)\n",
    "    Y_test.append(y)\n",
    "\n",
    "X_test = np.array(X_test, dtype=np.float32)\n",
    "Y_test = np.array(Y_test, dtype=np.float32)\n",
    "\n",
    "print(f\"  Total test cargadas: {len(X_test)} (Ignoradas en test: {ignored_eval})\")\n",
    "\n",
    "# Cargar el último modelo guardado para evaluar\n",
    "model = tf.keras.models.load_model(checkpoint_path, compile=True)\n",
    "metrics = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(f\"\\nResultados de evaluación: {metrics}\")\n",
    "\n",
    "# Reporte final\n",
    "print(f\"\\nTotal de imágenes ignoradas en entrenamiento: {ignored_images}\")\n",
    "\n",
    "def show_prediction(idx):\n",
    "    x, y = load_image_pair(idx)\n",
    "    if x is None or y is None:\n",
    "        print(\"No se pudo cargar la imagen o no está bien segmentada.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Formato de entrada (original): {x.shape}, Formato de salida: {y.shape}\")\n",
    "    print(\"Tipo de x:\", type(x), \"| dtype:\", x.dtype)\n",
    "\n",
    "    # Verifica que esté en el formato correcto\n",
    "    if x.shape != (512, 288, 3):\n",
    "        print(\"Redimensionando x...\")\n",
    "        x = tf.image.resize(x, (512, 288)).numpy()\n",
    "    if y.shape != (512, 288, 3):\n",
    "        print(\"Redimensionando y...\")\n",
    "        y = tf.image.resize(y, (512, 288)).numpy()\n",
    "\n",
    "    # Normaliza si es necesario\n",
    "    if x.max() > 1.0:\n",
    "        x = x / 255.0\n",
    "\n",
    "    # Asegura que tenga la dimensión de batch\n",
    "    x_batch = np.expand_dims(x, axis=0)\n",
    "    print(\"Forma para predicción:\", x_batch.shape)\n",
    "\n",
    "    # Predicción\n",
    "    pred = model.predict(x_batch)[0]\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Input\")\n",
    "    plt.imshow(x)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Ground Truth\")\n",
    "    plt.imshow(y)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(pred)\n",
    "    plt.show()\n",
    "\n",
    "show_prediction(3)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
